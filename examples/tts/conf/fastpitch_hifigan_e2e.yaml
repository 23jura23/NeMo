name: "FastPitch_HiFiGAN_E2E"

labels: [' ', '!', "'", '(', ')', ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g',
        'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
train_dataset: ???
validation_datasets: ???
test_datasets: null

sup_data_path: ???
sup_data_types: [ "duration_prior", "pitch", "durations" ]

phoneme_dict_path: "scripts/tts_dataset_files/cmudict-0.7b"
heteronyms_path: "scripts/tts_dataset_files/heteronyms-030921"
whitelist_path: "nemo_text_processing/text_normalization/en/data/whitelist_lj_speech.tsv"

model:
  learn_alignment: true
  sample_rate: 22050
  splice_length: 64
  lr: 3e-2
  labels: ${labels}
  n_speakers: 1
  symbols_embedding_dim: 384
  max_token_duration: 75
  n_mel_channels: 80
  pitch_embedding_kernel_size: 3
  mel_loss_coeff: 40
  hop_size: 256
  window: hann
  n_window_size: 1024
  n_window_stride: 256
  lowfreq: 0
  highfreq: 8000
  pitch_fmin: 80
  pitch_fmax: 640
  pitch_avg: 211.27540199742586
  pitch_std: 52.1851002822779

  train_ds:
    dataset:
      _target_: "nemo.collections.tts.torch.data.TTSDataset"
      manifest_filepath: ${train_dataset}
      sample_rate: ${model.sample_rate}
      sup_data_path: ${sup_data_path}
      sup_data_types: ${sup_data_types}
      n_fft: ${model.n_window_size}
      win_length: ${model.n_window_size}
      hop_length: ${model.n_window_stride}
      window: ${model.window}
      n_mels: ${model.n_mel_channels}
      lowfreq: ${model.lowfreq}
      highfreq: ${model.highfreq}
      max_duration: null
      min_duration: 0.1
      ignore_file: null
      trim: False
      pitch_fmin: ${model.pitch_fmin}
      pitch_fmax: ${model.pitch_fmax}
      pitch_norm: true
      pitch_avg: ${model.pitch_avg}
      pitch_std: ${model.pitch_std}

      text_normalizer:
        _target_: "nemo_text_processing.text_normalization.normalize.Normalizer"
        lang: "en"
        input_case: "cased"
        whitelist: ${whitelist_path}

      text_normalizer_call_args:
        verbose: False
        punct_pre_process: True
        punct_post_process: True

      text_tokenizer:
        _target_: "nemo.collections.tts.torch.tts_tokenizers.EnglishPhonemesTokenizer"
        punct: True
        stresses: True
        chars: True
        space: ' '
        silence: null
        apostrophe: True
        sep: '|'
        add_blank_at: null
        pad_with_space: True
        g2p:
          _target_: "nemo.collections.tts.torch.g2ps.EnglishG2p"
          phoneme_dict: ${phoneme_dict_path}
          heteronyms: ${heteronyms_path}
    dataloader_params:
      drop_last: false
      shuffle: true
      batch_size: 32
      num_workers: 12


  validation_ds:
    dataset:
      _target_: "nemo.collections.tts.torch.data.TTSDataset"
      manifest_filepath: ${validation_datasets}
      sample_rate: ${model.sample_rate}
      sup_data_path: ${sup_data_path}
      sup_data_types: ${sup_data_types}
      n_fft: ${model.n_window_size}
      win_length: ${model.n_window_size}
      hop_length: ${model.n_window_stride}
      window: ${model.window}
      n_mels: ${model.n_mel_channels}
      lowfreq: ${model.lowfreq}
      highfreq: ${model.highfreq}
      max_duration: null
      min_duration: null
      ignore_file: null
      trim: False
      pitch_fmin: ${model.pitch_fmin}
      pitch_fmax: ${model.pitch_fmax}
      pitch_norm: true
      pitch_avg: ${model.pitch_avg}
      pitch_std: ${model.pitch_std}

      text_normalizer:
        _target_: "nemo_text_processing.text_normalization.normalize.Normalizer"
        lang: "en"
        input_case: "cased"
        whitelist: ${whitelist_path}

      text_normalizer_call_args:
        verbose: False
        punct_pre_process: True
        punct_post_process: True

      text_tokenizer:
        _target_: "nemo.collections.tts.torch.tts_tokenizers.EnglishPhonemesTokenizer"
        punct: True
        stresses: True
        chars: True
        space: ' '
        silence: null
        apostrophe: True
        sep: '|'
        add_blank_at: null
        pad_with_space: True
        g2p:
          _target_: "nemo.collections.tts.torch.g2ps.EnglishG2p"
          phoneme_dict: ${phoneme_dict_path}
          heteronyms: ${heteronyms_path}

    dataloader_params:
      drop_last: false
      shuffle: false
      batch_size: 32
      num_workers: 8

#  train_ds:
#    manifest_filepath: ${train_dataset}
#    max_duration: null
#    min_duration: 0.1
#    sample_rate: ${model.sample_rate}
#    trim: false
#    parser: null
#    drop_last: true
#    shuffle: true
#    batch_size: 64
#    num_workers: 12
#
#  validation_ds:
#    manifest_filepath: ${validation_datasets}
#    sample_rate: ${model.sample_rate}
#    trim: false
#    parser: null
#    drop_last: false
#    shuffle: false
#    batch_size: 64
#    num_workers: 8

  preprocessor:
    _target_: nemo.collections.asr.parts.preprocessing.features.FilterbankFeatures
    dither: 0.0
    nfilt: ${model.n_mel_channels}
    frame_splicing: 1
    highfreq: 8000
    log: true
    log_zero_guard_type: clamp
    log_zero_guard_value: 1e-05
    lowfreq: 0
    mag_power: 1.0
    n_fft: 1024
    n_window_size: 1024
    n_window_stride: ${model.hop_size}
    normalize: null
    pad_to: 1
    pad_value: 0
    preemph: null
    sample_rate: ${model.sample_rate}
    window: hann
    exact_pad: true
    use_grads: false

  input_fft:
    _target_: nemo.collections.tts.modules.transformer.FFTransformerEncoder
    n_layer: 6
    n_head: 1
    d_model: ${model.symbols_embedding_dim}
    d_head: 64
    d_inner: 1536
    kernel_size: 3
    dropout: 0.1
    dropatt: 0.1
    dropemb: 0.0
    n_embed: 148  # NOTE Should match # of tokens in `symbol_set`
    d_embed: ${model.symbols_embedding_dim}
    padding_idx: 0

  output_fft:
    _target_: nemo.collections.tts.modules.transformer.FFTransformerDecoder
    n_layer: 6
    n_head: 1
    d_model: ${model.symbols_embedding_dim}
    d_head: 64
    d_inner: 1536
    kernel_size: 3
    dropout: 0.1
    dropatt: 0.1
    dropemb: 0.0

  duration_predictor:
    _target_: nemo.collections.tts.modules.fastpitch.TemporalPredictor
    input_size: ${model.symbols_embedding_dim}
    kernel_size: 3
    filter_size: 256
    dropout: 0.1
    n_layers: 2

  pitch_predictor:
    _target_: nemo.collections.tts.modules.fastpitch.TemporalPredictor
    input_size: ${model.symbols_embedding_dim}
    kernel_size: 3
    filter_size: 256
    dropout: 0.1
    n_layers: 2

  generator:
    _target_: nemo.collections.tts.modules.hifigan_modules.Generator
    upsample_kernel_sizes: [16,16,4,4]
    upsample_rates: [8,8,2,2]
    upsample_initial_channel: 512
    resblock_kernel_sizes: [3,7,11]
    resblock_dilation_sizes: [[1,3,5], [1,3,5], [1,3,5]]
    resblock: 1
    initial_input_size: 384

trainer:
  gpus: -1 # number of gpus
  max_epochs: 1500
  num_nodes: 1
  accelerator: ddp
  accumulate_grad_batches: 1
  checkpoint_callback: False  # Provided by exp_manager
  logger: False  # Provided by exp_manager
  gradient_clip_val: 1000.0
  flush_logs_every_n_steps: 1000
  log_every_n_steps: 100
  check_val_every_n_epoch: 5
  precision: 16

exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: True
  create_checkpoint_callback: True
